{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jy7lsna/PyTorch-Notes/blob/main/03_PyTorch_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkObAS4g8rHf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8uNuONZK8iY"
      },
      "outputs": [],
      "source": [
        "# setting up training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "# setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2_pQw4BMgHS"
      },
      "outputs": [],
      "source": [
        "# see first training sample\n",
        "image, label = train_data[0]\n",
        "image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBcq2qoUMqWB"
      },
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOVGzF5XNJ-j"
      },
      "outputs": [],
      "source": [
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PZN-MmONXyf"
      },
      "outputs": [],
      "source": [
        "# classes\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MafryQ2UNivQ"
      },
      "outputs": [],
      "source": [
        "# visualizing our data\n",
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0rTi7sPN09t"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"grey\")\n",
        "plt.title(class_names[label]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl4MrG4ZN947"
      },
      "outputs": [],
      "source": [
        "# plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2EDXAvnv8D6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# turn datasets into batches\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "print(f\"DataLoaders: {train_data, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGp_dglbwyZL"
      },
      "outputs": [],
      "source": [
        "train_featues_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_featues_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuvnomYHw_w6"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_featues_batch), size=[1]).item()\n",
        "img, label = train_featues_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lUQojTJxuwL"
      },
      "source": [
        "# **Data Loaded and prepared!**\n",
        "Time to build a **Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXWdNmugxtmv"
      },
      "outputs": [],
      "source": [
        "# create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# get a single sampple\n",
        "x = train_featues_batch[0]\n",
        "\n",
        "# flatten sample\n",
        "output = flatten_model(x)\n",
        "\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n",
        "\n",
        "print(x)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnwvO0e4y2Q0"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro7awDga0CbE"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = FashionMNISTModelV0(input_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names))\n",
        "\n",
        "model_0.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjmOtWJ0URO"
      },
      "source": [
        "# **Setup loss, optimizer and veal metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-UycZ2q0TdL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhnsIWTs0gC1"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6fEubQ04R0"
      },
      "source": [
        "# **Creating a function to time our experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nNXgPLa09P8"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Irdxf_h1E7r"
      },
      "source": [
        "# **Creating a training loop and training model on batches of data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZP2SsRd1JzX"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  # training\n",
        "  train_loss = 0\n",
        "  # loop to train thru training batches\n",
        "  for batch, (x, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward Pass\n",
        "    y_pred = model_0(x)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    #  3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #  4. Loss Backward\n",
        "    loss.backward()\n",
        "\n",
        "    #  5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 480 == 0:\n",
        "      print(f\"Looked at {batch * len(x)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  # testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for x, y in test_dataloader:\n",
        "      # 1. Fowrad pass\n",
        "      test_pred = model_0(x)\n",
        "\n",
        "      # 2. Calculate loss\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "\n",
        "      #  3. Calculate acc\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "\n",
        "# calc training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaEBLHeV38fc"
      },
      "source": [
        "# **Make predictions and get Model 0 results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sMHQtSw4AQP"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,):\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for x, y in data_loader:\n",
        "      y_pred = model(x)\n",
        "\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n",
        "\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhpv15XQb-Bz"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJjmLh6d5zrV"
      },
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWdo6d7HTmUJ"
      },
      "outputs": [],
      "source": [
        "# building another model with non linearity\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(), #flatten inputs into a single vector\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR28JFj3U9bh"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(input_shape=784,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)\n",
        "next(model_1.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwUSulCAWYxe"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X2SpISCWpTl"
      },
      "outputs": [],
      "source": [
        "# training and test loops\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "  for batch, (x, y) in enumerate(data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for x, y in data_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(x)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true=y,\n",
        "                              y_pred=test_pred.argmax(dim=1)\n",
        "                              )\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9p56HnvZSrj"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epochs: {epoch}\\n------\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "  test_step(data_loader=test_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ow0QUd9ccS-"
      },
      "outputs": [],
      "source": [
        "# move values to device\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for x, y in data_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_pred = model(x)\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n",
        "\n",
        "model_1_results = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h0oxQEgn9xx"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBeOgjnnimhd"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAeJWKmFdNA6"
      },
      "outputs": [],
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IxdaDoAlkaE"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# smaple batch w random numbers\n",
        "images = torch.randn(size=(32, 3, 64, 64))\n",
        "test_image = images[0]\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Single Image pixel values:\\n {test_image}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB9EsI8ym5VB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=0) # also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKl0EIPoXYw"
      },
      "outputs": [],
      "source": [
        "test_image.unsqueeze(dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlpTx8QNojEd"
      },
      "outputs": [],
      "source": [
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0Ki4QYYpCYA"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "# new conv layer w diff values\n",
        "conv_layer_2 = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=(5, 5),\n",
        "                       stride=2,\n",
        "                       padding=0) # also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer_2(test_image.unsqueeze(dim=0)).shape # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXIbWgax0CtE"
      },
      "outputs": [],
      "source": [
        "print(conv_layer_2.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfD-R3rY0My_"
      },
      "outputs": [],
      "source": [
        "# Get shapes of weight and bias tensors within conv_layer_2\n",
        "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
        "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94NAJ8bE7jbU"
      },
      "outputs": [],
      "source": [
        "print(f\"test image original shape: {test_image.shape}\")\n",
        "print(f\"test image without unsqueezed dimesnion: {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv_layer() and max_layer(): {test_image_through_conv_and_max_pool.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ziEBTW98SIY"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
        "print(f\"Random tensor: \\n{random_tensor}\")\n",
        "print(f\"random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor: \\n{max_pool_tensor}\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cfnC1JR_8ii"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOvYIb-sAGeO"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epochs}\\n-----\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "             model=model_2,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device\n",
        "             )\n",
        "  test_step(data_loader=test_dataloader,\n",
        "            model=model_2,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device\n",
        "            )\n",
        "\n",
        "  train_time_end_model_2 = timer()\n",
        "  total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                               end=train_time_end_model_2,\n",
        "                                               device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz2mZ1vrBboe"
      },
      "outputs": [],
      "source": [
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtlUVQiSBwaW"
      },
      "source": [
        "# **Compare model results and training time**\n",
        "- model_0 - our baseline model with two nn.Linear() layers.\n",
        "\n",
        "- model_1 - the same setup as our baseline model except with nn.ReLU() layers in between the nn.Linear() layers.\n",
        "\n",
        "- model_2 - our first CNN model that mimics the TinyVGG architecture on the CNN Explainer website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNwgikyMB8Ta"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgAiIQPyCIWG"
      },
      "outputs": [],
      "source": [
        "# add training values\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0, total_train_time_model_1, total_train_time_model_2]\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOBG5muaCsrA"
      },
      "outputs": [],
      "source": [
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"Accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8lq7CbYC-55"
      },
      "source": [
        "# **Make and evaluate random predictions with best model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ivgfwC-C-mw"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLYu4GilDt7B"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtyuRe7yEMKO"
      },
      "outputs": [],
      "source": [
        "pred_probs = make_predictions(model=model_2, data=test_samples)\n",
        "\n",
        "pred_probs[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEbCB804EVZx"
      },
      "outputs": [],
      "source": [
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p5pXQUHEe4E"
      },
      "outputs": [],
      "source": [
        "test_labels, pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKrsuHsmEkwI"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "  plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THewq7Q0Fl93"
      },
      "source": [
        "# **Confusion matrix for further evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CmPMkTLKFo_2"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for x, y in tqdm(test_dataloader, desc=\"making predictions\"):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    y_logit = model_2(x)\n",
        "\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
        "\n",
        "    y_preds.append(y_pred.cpu())\n",
        "\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zuXKVCFwGMDj"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "  assert int(mlxtend.__version__.split(\".\")[1]) >= 19\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5gCNR3pAG20D"
      },
      "outputs": [],
      "source": [
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "phn2oTU0HDgX"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names), task=\"multiclass\")\n",
        "confmat_tensor = confmat(preds=y_pred_tensor, target=test_data.targets)\n",
        "\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(),\n",
        "    class_names=class_names,\n",
        "    figsize=(10, 7)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VWrSI8KrH39K"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"03_PyTorch_Computer_Vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(), f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c7ev-UAIaa0"
      },
      "outputs": [],
      "source": [
        "# Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())\n",
        "# Note: loading model will error if the shapes here aren't the same as the saved version\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                    hidden_units=10, # try changing this to 128 and seeing what happens\n",
        "                                    output_shape=10)\n",
        "\n",
        "# Load in the saved state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to GPU\n",
        "loaded_model_2 = loaded_model_2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B9vqUiYIcb5"
      },
      "outputs": [],
      "source": [
        "# Evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(\n",
        "    model=loaded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzKtE215IgDv"
      },
      "outputs": [],
      "source": [
        "# Check to see if results are close to each other (if they are very far away, there may be an error)\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol=1e-08, # absolute tolerance\n",
        "              rtol=0.0001) # relative tolerance"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMSP8vYlyxAc/pSDjQTI0Ei",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}